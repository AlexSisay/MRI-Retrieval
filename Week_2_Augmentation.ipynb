{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfd352f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/.local/lib/python3.8/site-packages/nilearn/datasets/__init__.py:93: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    }
   ],
   "source": [
    "from nilearn import plotting\n",
    "import pylab as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "from scipy.ndimage import affine_transform\n",
    "from scipy.ndimage import rotate\n",
    "import albumentations as albu\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform, DualTransform\n",
    "from scipy.stats import multivariate_normal\n",
    "import cv2\n",
    "#from cerebrum.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20ed1c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addWeighted(src1, alpha, src2, beta, gamma):\n",
    "    \"\"\" \n",
    "    Calculates the weighted sum of two arrays (cv2 replaced).\n",
    "\n",
    "    :param src1: first input array.\n",
    "    :param aplha: weight of the first array elements.\n",
    "    :param src2: second input array of the same size and channel number as src1.\n",
    "    :param beta: weight of the second array elements.\n",
    "    :param gamma: scalar added to each sum\n",
    "    :return: output array that has the same size and number of channels as the input arrays.\n",
    "    \"\"\"\n",
    "\n",
    "    return src1 * alpha + src2 * beta + gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25ebe5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation_salt_and_pepper_noise(X_data, amount=10. / 1000):\n",
    "    \"\"\" \n",
    "    Function to add S&P noise to the volume.\n",
    "\n",
    "    :param X_data: input volume (3D) -> shape (x,y,z)\n",
    "    :param amount: quantity of voxels affected\n",
    "    :return X_data_out: augmented volume\n",
    "    \"\"\"\n",
    "\n",
    "    X_data_out = X_data\n",
    "    salt_vs_pepper = 0.2  # Ration between salt and pepper voxels\n",
    "    n_salt_voxels = int(np.ceil(amount * np.prod(X_data_out.size) * salt_vs_pepper))\n",
    "    n_pepper_voxels = int(np.ceil(amount * np.prod(X_data_out.size) * (1.0 - salt_vs_pepper)))\n",
    "\n",
    "    # Add Salt noise\n",
    "    coords = [np.random.randint(0, i - 1, int(n_salt_voxels)) for i in np.squeeze(X_data_out).shape]\n",
    "    X_data_out[coords[0], coords[1], coords[2]] = np.max(X_data)\n",
    "\n",
    "    # Add Pepper noise\n",
    "    coords = [np.random.randint(0, i - 1, int(n_pepper_voxels)) for i in np.squeeze(X_data_out).shape]\n",
    "    X_data_out[coords[0], coords[1], coords[2]] = np.min(X_data)\n",
    "\n",
    "    return X_data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b04b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation_gaussian_noise(X_data):\n",
    "    \"\"\" \n",
    "    Function to add gaussian noise to the volume.\n",
    "\n",
    "    :param X_data: input volume (3D) -> shape (x,y,z)\n",
    "    :return X_data_out: augmented volume\n",
    "    \"\"\"\n",
    "\n",
    "    # Gaussian distribution parameters\n",
    "    X_data_no_background = X_data\n",
    "    mean = np.mean(X_data_no_background)\n",
    "    var = np.var(X_data_no_background)\n",
    "    sigma = var ** 0.5\n",
    "\n",
    "    gaussian = np.random.normal(mean, sigma, X_data.shape).astype(X_data.dtype)\n",
    "\n",
    "    # Compose the output (src1, alpha, src2, beta, gamma)\n",
    "    X_data_out = addWeighted(X_data, 0.8, gaussian, 0.2, 0)\n",
    "\n",
    "    return X_data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22b5d4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation_inhomogeneity_noise(X_data, inhom_vol):\n",
    "    \"\"\" \n",
    "    Function to add inhomogeneity noise to the volume.\n",
    "\n",
    "    :param X_data: input volume (3D) -> shape (x,y,z)\n",
    "    :param inhom_vol: inhomogeneity volume (preloaded)\n",
    "    :return X_data_out: augmented volume\n",
    "    \"\"\"\n",
    "\n",
    "    # Randomly select a vol of the same shape of 'X_data'\n",
    "    x_1 = np.random.randint(0, int(X_data.shape[0]) - 1, size=1)[0]\n",
    "    x_2 = np.random.randint(0, int(X_data.shape[1]) - 1, size=1)[0]\n",
    "    x_3 = np.random.randint(0, int(X_data.shape[2]) - 1, size=1)[0]\n",
    "    y_1 = inhom_vol[x_1: x_1 + X_data.shape[0],\n",
    "          x_2: x_2 + X_data.shape[1],\n",
    "          x_3: x_3 + X_data.shape[2]]\n",
    "\n",
    "    # Compose the output: add noise to the original vol\n",
    "    X_data_out = X_data + y_1.astype(X_data.dtype)\n",
    "\n",
    "    return X_data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dae52a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_volume(image,\n",
    "                     shift_x0: int, shift_x1: int, shift_x2: int,\n",
    "                     padding_mode: str = 'nearest',\n",
    "                     spline_interp_order: int = 1):\n",
    "    \"\"\" \n",
    "    Function to apply volume translation to a single volume.\n",
    "\n",
    "    :param image: input volume (3D) -> shape (x,y,z)\n",
    "    :param shift_x0-shift_x1-shift_x2: shift in voxels\n",
    "    :param padding_mode: the padding mode\n",
    "    :param spline_interp_order: order for the affine transformation\n",
    "    :return: augmented volume\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the affine transformation matrix\n",
    "    M_t = np.eye(4)\n",
    "    M_t[:-1, -1] = np.array([-shift_x0, -shift_x1, -shift_x2])\n",
    "\n",
    "    return affine_transform(image, M_t,\n",
    "                            order=spline_interp_order,\n",
    "                            mode=padding_mode,\n",
    "                            cval=0,\n",
    "                            output_shape=image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9f6f9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TranslationAugment(img, shift_x0: int = 0, shift_x1: int = 0, shift_x2: int = 0):\n",
    "    \"\"\" Function to deal with translation augmentation. \"\"\"\n",
    "        # Apply to image or mask\n",
    "    if np.issubdtype(img.dtype, np.floating):  # image\n",
    "        img_out = translate_volume(img,\n",
    "                                   shift_x0, shift_x1, shift_x2,\n",
    "                                   padding_mode='nearest',\n",
    "                                   spline_interp_order=1)\n",
    "    elif np.issubdtype(img.dtype, np.integer):  # mask\n",
    "        img_out = translate_volume(img,\n",
    "                                   shift_x0, shift_x1, shift_x2,\n",
    "                                   padding_mode='constant',\n",
    "                                   spline_interp_order=0)\n",
    "    else:\n",
    "        raise Exception('Error 23: type not supported.')\n",
    "\n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99e484e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RotationAugment(img,max_angle: int = 10, rot_spline_order: int = 3,always_apply=False,p=1.0):\n",
    "        \"\"\" Function to deal with rotation augmentation. \"\"\"\n",
    "        random_angle = np.random.RandomState().randint(2 * max_angle) - max_angle\n",
    "        rot_axes = np.random.RandomState().permutation(range(3))[:2]  # random select the 2 rotation axes\n",
    "        # Apply to image or mask\n",
    "        if np.issubdtype(img.dtype, np.floating):  # image\n",
    "            img_out = rotate(input=img,\n",
    "                             angle=random_angle,\n",
    "                             axes=rot_axes,\n",
    "                             reshape=False,\n",
    "                             order=rot_spline_order,\n",
    "                             mode='nearest',\n",
    "                             prefilter=True)\n",
    "        elif np.issubdtype(img.dtype, np.integer):  # mask\n",
    "            img_out = rotate(input=img,\n",
    "                             angle=random_angle,\n",
    "                             axes=rot_axes,\n",
    "                             reshape=False,\n",
    "                             order=0,\n",
    "                             mode='constant',\n",
    "                             prefilter=True)\n",
    "        else:\n",
    "            raise Exception('Error 24: type not supported.')\n",
    "\n",
    "        return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3f5a262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GhostingAugment(img,max_repetitions: int = 4, always_apply=False, p=1.0):\n",
    "    \"\"\"Function to deal with ghosting augmentation. \"\"\"\n",
    "        # Randomly select parameters\n",
    "    repetitions = np.random.RandomState().choice(range(1, max_repetitions + 1))\n",
    "    axis = np.random.RandomState().choice(range(len(img.shape)))\n",
    "\n",
    "    img_out = img\n",
    "    shift_value = 0\n",
    "    for i_rep in range(1, repetitions + 1):\n",
    "        # Compute the shift to apply to the data\n",
    "        shift_value += int(img.shape[axis] / (i_rep + 1))\n",
    "\n",
    "        # Shift the data and add to the out volume\n",
    "        data_repetition = np.roll(img, shift_value, axis=axis)\n",
    "        img_out = addWeighted(img_out, 0.85, data_repetition, 0.15, 0)\n",
    "\n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adee0ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation_inhomogeneity_noise(X_data, inhom_vol):\n",
    "    \"\"\" \n",
    "    Function to add inhomogeneity noise to the volume.\n",
    "\n",
    "    :param X_data: input volume (3D) -> shape (x,y,z)\n",
    "    :param inhom_vol: inhomogeneity volume (preloaded)\n",
    "    :return X_data_out: augmented volume\n",
    "    \"\"\"\n",
    "    # Randomly select a vol of the same shape of 'X_data'\n",
    "    x_1 = np.random.randint(0, int(X_data.shape[0]) - 1, size=1)[0]\n",
    "    x_2 = np.random.randint(0, int(X_data.shape[1]) - 1, size=1)[0]\n",
    "    x_3 = np.random.randint(0, int(X_data.shape[2]) - 1, size=1)[0]\n",
    "    y_1 = inhom_vol[x_1: x_1 + X_data.shape[0],\n",
    "          x_2: x_2 + X_data.shape[1],\n",
    "          x_3: x_3 + X_data.shape[2]]\n",
    "    # Compose the output: add noise to the original vol\n",
    "    X_data_out = X_data + y_1.astype(X_data.dtype)\n",
    "\n",
    "    return X_data_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1453250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augm_transforms(inho_vol, volume_size: int = 128):\n",
    "    \"\"\"\n",
    "    Get the transformations for volume (and mask) augmentation.\n",
    "\n",
    "    :param inho_vol: inhomogeneity volume\n",
    "    :param volume_size: size of the volume\n",
    "    :param config: Config class (with all probabilities stored)\n",
    "    :return: albumentation composition\n",
    "    \"\"\"\n",
    "\n",
    "    return albu.Compose([\n",
    "\n",
    "        # Default transformations\n",
    "        albu.VerticalFlip(p = 0.8),  # sagittal plane\n",
    "        InhomogeneityNoiseAugment(inho_vol, p = 0.8),  # Inhomogeneity noise\n",
    "\n",
    "        # Geometric transformations\n",
    "        albu.OneOf([\n",
    "            albu.GridDistortion(num_steps = 5,\n",
    "                                distort_limit = (-0.10, +0.10),\n",
    "                                interpolation = 4,\n",
    "                                border_mode = 1,\n",
    "                                p = 0.4),\n",
    "            albu.RandomResizedCrop(height = volume_size,\n",
    "                                   width = volume_size,\n",
    "                                   scale = (0.9, 1.0),\n",
    "                                   ratio = (0.8, 1.20),\n",
    "                                   interpolation = 4,\n",
    "                                   p = 0.3),\n",
    "            RotationAugment(p = 0.5),\n",
    "            TranslationAugment(p = 0.2),\n",
    "        ], p = 1.0),\n",
    "\n",
    "        # Color transformations\n",
    "        albu.OneOf([\n",
    "            albu.Blur(blur_limit = (3, 3), p = 0.4),\n",
    "            albu.Downscale(scale_min = 0.6, \n",
    "                           scale_max = 0.99, \n",
    "                           interpolation = 4, \n",
    "                           p = 0.5),\n",
    "            SaltAndPepperNoiseAugment(p = 0.4),\n",
    "            GaussianNoiseAugment(p = 0.8),\n",
    "            GhostingAugment(p = 0.5),\n",
    "        ], p = 0.8),\n",
    "\n",
    "    ], p = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45b31856",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '/Users/alex/Documents/MATLAB/data/shepp-logan-dataset/'\n",
    "basename = 'shepp_logan_'\n",
    "fileext  = '.nii.gz'\n",
    "img = []\n",
    "img_mask = []\n",
    "for id in range(0,9): \n",
    "    fileid = '%05d'%id\n",
    "    IDdirpath = dir + fileid;\n",
    "    filename = IDdirpath + '/'+ basename + fileid + fileext\n",
    "    maskfilename = IDdirpath + '/' + basename + fileid + '_mask'+ fileext\n",
    "    img_name = nb.load(filename)\n",
    "    img_m = nb.load(maskfilename)\n",
    "    img.append(img_name)\n",
    "    img_mask.append(img_m)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "709e22e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inhom_vol(img):\n",
    "    molt_factor = 2\n",
    "    max_value = 0.5                     # max (or min) = 0.25 (-0.25) \n",
    "    t1 = img #[:,:,:,0]\n",
    "    # create axis\n",
    "    x_1 = np.linspace(0, 1, int(t1.shape[0]*molt_factor), endpoint=True)\n",
    "    x_2 = np.linspace(0, 1, int(t1.shape[1]*molt_factor), endpoint=True)\n",
    "    x_3 = np.linspace(0, 1, int(t1.shape[2]*molt_factor), endpoint=True)\n",
    "    x_1,x_2,x_3 = np.meshgrid(x_1,x_2,x_3)\n",
    "    pos = np.stack((x_1, x_2, x_3),axis=-1)\n",
    "    # create distrs\n",
    "    mean = [0.5, 0.5, 0.5]\n",
    "    cov = [[2.0, 0.3, 0.3], [0.3, 2.0, 0.3], [0.3, 0.3, 2.0]]\n",
    "    rv = multivariate_normal(mean, cov, allow_singular=True)\n",
    "    y = rv.pdf(pos)             # derive distribution\n",
    "    y -= np.mean(y)             # standardisation (I want across zero)\n",
    "    y = y / max(y.max(), np.abs(y.min())) * max_value\n",
    "    y = np.transpose(y, (1, 0, 2))      # swap axes\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "886e63e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img0 with Salt & Pepper Noise.....Saved\n",
      "img0 with Gaussian Noise.....Saved\n",
      "Translated img0 .....Saved\n",
      "Rotated img0 .....Saved\n",
      "Ghosted img0 .....Saved\n",
      "img0 with Inhomogeniety noise.....Saved\n",
      "img1 with Salt & Pepper Noise.....Saved\n",
      "img1 with Gaussian Noise.....Saved\n",
      "Translated img1 .....Saved\n",
      "Rotated img1 .....Saved\n",
      "Ghosted img1 .....Saved\n",
      "img1 with Inhomogeniety noise.....Saved\n",
      "img2 with Salt & Pepper Noise.....Saved\n",
      "img2 with Gaussian Noise.....Saved\n",
      "Translated img2 .....Saved\n",
      "Rotated img2 .....Saved\n",
      "Ghosted img2 .....Saved\n",
      "img2 with Inhomogeniety noise.....Saved\n",
      "img3 with Salt & Pepper Noise.....Saved\n",
      "img3 with Gaussian Noise.....Saved\n",
      "Translated img3 .....Saved\n",
      "Rotated img3 .....Saved\n",
      "Ghosted img3 .....Saved\n",
      "img3 with Inhomogeniety noise.....Saved\n",
      "img4 with Salt & Pepper Noise.....Saved\n",
      "img4 with Gaussian Noise.....Saved\n",
      "Translated img4 .....Saved\n",
      "Rotated img4 .....Saved\n",
      "Ghosted img4 .....Saved\n",
      "img4 with Inhomogeniety noise.....Saved\n",
      "img5 with Salt & Pepper Noise.....Saved\n",
      "img5 with Gaussian Noise.....Saved\n",
      "Translated img5 .....Saved\n",
      "Rotated img5 .....Saved\n",
      "Ghosted img5 .....Saved\n",
      "img5 with Inhomogeniety noise.....Saved\n",
      "img6 with Salt & Pepper Noise.....Saved\n",
      "img6 with Gaussian Noise.....Saved\n",
      "Translated img6 .....Saved\n",
      "Rotated img6 .....Saved\n",
      "Ghosted img6 .....Saved\n",
      "img6 with Inhomogeniety noise.....Saved\n",
      "img7 with Salt & Pepper Noise.....Saved\n",
      "img7 with Gaussian Noise.....Saved\n",
      "Translated img7 .....Saved\n",
      "Rotated img7 .....Saved\n",
      "Ghosted img7 .....Saved\n",
      "img7 with Inhomogeniety noise.....Saved\n",
      "img8 with Salt & Pepper Noise.....Saved\n",
      "img8 with Gaussian Noise.....Saved\n",
      "Translated img8 .....Saved\n",
      "Rotated img8 .....Saved\n",
      "Ghosted img8 .....Saved\n",
      "img8 with Inhomogeniety noise.....Saved\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#Salt & Pepper Noise\n",
    "for id in range(0,9):\n",
    "    fileid = '%05d'%id\n",
    "    IDdirpath = dir + fileid;\n",
    "    \n",
    "    vol_out = np.copy(img[id].get_fdata())\n",
    "    vol_out_m = np.copy(img_mask[id].get_fdata())\n",
    "\n",
    "    #################### Salt & Pepper Noise ################################## \n",
    "    vol_s_p = augmentation_salt_and_pepper_noise(vol_out)\n",
    "    vol_s_p_m = augmentation_salt_and_pepper_noise(vol_out_m)\n",
    "    vol_s_p = nb.Nifti1Image(vol_s_p,affine = img[id].header.get_sform(), header = img[id].header)\n",
    "    vol_s_p_m = nb.Nifti1Image(vol_s_p_m,affine = img_mask[id].header.get_sform(), header = img_mask[id].header)\n",
    "    filename = IDdirpath + '/'+ basename + fileid + '_S&P' + fileext\n",
    "    maskfilename = IDdirpath + '/' + basename + fileid + '_S&P_mask'+ fileext    \n",
    "    nb.save(vol_s_p,filename) #Salt & Pepper Noise\n",
    "    nb.save(vol_s_p_m,maskfilename) #Salt & Pepper Noise\n",
    "    print('img%d with Salt & Pepper Noise.....Saved'%id) #Salt & Pepper Noise\n",
    "\n",
    "    #################### Gaussian Noise ################################## \n",
    "    vol_out_gn = augmentation_gaussian_noise(vol_out)\n",
    "    vol_out_gn_m = augmentation_gaussian_noise(vol_out_m)    \n",
    "    vol_out_gn = nb.Nifti1Image(vol_out_gn,affine = img[id].header.get_sform(), header = img[id].header)\n",
    "    vol_out_gn_m = nb.Nifti1Image(vol_out_gn_m,affine = img_mask[id].header.get_sform(), header = img_mask[id].header)\n",
    "    filename = IDdirpath + '/'+ basename + fileid + '_GN' + fileext\n",
    "    maskfilename = IDdirpath + '/' + basename + fileid + '_GN_mask'+ fileext    \n",
    "    nb.save(vol_out_gn,filename) #Gaussian Noise \n",
    "    nb.save(vol_out_gn_m,maskfilename) #Gaussian Noise \n",
    "    print('img%d with Gaussian Noise.....Saved'%id) #Gaussian Noise  \n",
    "    \n",
    "    #################### Translation ##################################    \n",
    "    vol_out_trans = TranslationAugment(vol_out,shift_x0 = 0,shift_x1 = 30,shift_x2 = 0)\n",
    "    vol_out_trans_m = TranslationAugment(vol_out_m,shift_x0 = 0,shift_x1 = 30,shift_x2 = 0)\n",
    "    vol_out_trans = nb.Nifti1Image(vol_out_trans,affine = img[id].header.get_sform(), header = img[id].header)\n",
    "    vol_out_trans_m = nb.Nifti1Image(vol_out_trans_m,affine = img_mask[id].header.get_sform(), header = img_mask[id].header)    \n",
    "    filename = IDdirpath + '/'+ basename + fileid + '_Trans' + fileext\n",
    "    maskfilename = IDdirpath + '/' + basename + fileid + '__Trans_mask'+ fileext    \n",
    "    nb.save(vol_out_trans,filename) #Translation  \n",
    "    nb.save(vol_out_trans_m,maskfilename) #Translation\n",
    "    print('Translated img%d .....Saved'%id) #Translation \n",
    "    \n",
    "    #################### Rotation ##################################\n",
    "    vol_out_rot = RotationAugment(vol_out)\n",
    "    vol_out_rot_m = RotationAugment(vol_out_m)\n",
    "    vol_out_rot = nb.Nifti1Image(vol_out_rot,affine = img[id].header.get_sform(), header = img[id].header)\n",
    "    vol_out_rot_m = nb.Nifti1Image(vol_out_rot_m,affine = img_mask[id].header.get_sform(), header = img_mask[id].header) \n",
    "    filename = IDdirpath + '/'+ basename + fileid + '_Rot' + fileext\n",
    "    maskfilename = IDdirpath + '/' + basename + fileid + '__Rot_mask'+ fileext    \n",
    "    nb.save(vol_out_rot,filename) #Rotation  \n",
    "    nb.save(vol_out_rot_m,maskfilename) #Rotation\n",
    "    print('Rotated img%d .....Saved'%id) #Rotation \n",
    "    \n",
    "    #################### Ghosting ##################################\n",
    "    vol_out_gho = GhostingAugment(vol_out)\n",
    "    vol_out_gho_m = GhostingAugment(vol_out_m)\n",
    "    vol_out_gho = nb.Nifti1Image(vol_out_gho,affine = img[id].header.get_sform(), header = img[id].header)\n",
    "    vol_out_gho_m = nb.Nifti1Image(vol_out_gho_m,affine = img_mask[id].header.get_sform(), header = img_mask[id].header) \n",
    "    filename = IDdirpath + '/'+ basename + fileid + '_Gho' + fileext\n",
    "    maskfilename = IDdirpath + '/' + basename + fileid + '__Gho_mask'+ fileext    \n",
    "    nb.save(vol_out_gho,filename) #Ghosting  \n",
    "    nb.save(vol_out_gho_m,maskfilename) #Ghosting\n",
    "    print('Ghosted img%d .....Saved'%id) #Ghosting \n",
    "      \n",
    "\n",
    "    ############################ Inhomogeneity_noise ###################################\n",
    "    y = inhom_vol(vol_out)\n",
    "    y_m = inhom_vol(vol_out_m)\n",
    "    vol_out_inhom = augmentation_inhomogeneity_noise(vol_out,y)\n",
    "    vol_out_inhom_m = augmentation_inhomogeneity_noise(vol_out_m,y_m)\n",
    "    vol_out_inhom = nb.Nifti1Image(vol_out_inhom,affine = img[id].header.get_sform(), header = img[id].header)\n",
    "    vol_out_inhom_m = nb.Nifti1Image(vol_out_inhom_m,affine = img_mask[id].header.get_sform(), header = img_mask[id].header) \n",
    "    filename = IDdirpath + '/'+ basename + fileid + '_InhoN' + fileext\n",
    "    maskfilename = IDdirpath + '/' + basename + fileid + '__InhoN_mask'+ fileext    \n",
    "    nb.save(vol_out_inhom,filename) #Inhomogeniety  \n",
    "    nb.save(vol_out_inhom_m,maskfilename) #Inhomogeniety\n",
    "    print('img%d with Inhomogeniety noise.....Saved'%id) #Inhomogeniety \n",
    "\n",
    "print('Done!')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8b031c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = albu.OneOf([\n",
    "    #albu.GridDistortion(num_steps = 5,distort_limit = (-0.10, +0.10),interpolation = 4,border_mode = 1,p = 1),    \n",
    "    # Default transformations\n",
    "    #albu.VerticalFlip(p = 1.),  # sagittal plane\n",
    "    #albu.RandomResizedCrop(height = 45, width = 67, scale = (0.9, 0.9), ratio = (0.8, 1.20), interpolation = 4,  p = 1),\n",
    "    #albu.Blur(always_apply = False, p=1.0, blur_limit = (3,3)),\n",
    "    #albu.CLAHE(always_apply=False, p=1.0, clip_limit = (1,2), tile_grid_size=(8,8)),\n",
    "    #albu.Downscale(always_apply = False, p=1.0, scale_min=0.6, interpolation=4),\n",
    "    #albu.ImageCompression(always_apply=False, p=1.0, quality_lower=90, quality_upper=100,compression_type=0),\n",
    "    #albu.RandomGamma(always_apply=False, p=1.0,gamma_limit=(101,101),eps=1e-07),\n",
    "    #albu.CenterCrop(always_apply=False, p=1.0,height=100,width=100),\n",
    "    #albu.HorizontalFlip(always_apply=False, p=1.0),\n",
    "    albu.ShiftScaleRotate(always_apply=False, p=1.0,shift_limit=(+0.05,0.05), scale_limit=(+0.1,0.1),\n",
    "                          rotate_limit=(+5,5),interpolation=4, border_mode=1, value=(0,0,0), mask_value=None),\n",
    "\n",
    "    \n",
    "], p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d2f051c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img0 with Shift Scale Rotate  .....Saved\n",
      "img1 with Shift Scale Rotate  .....Saved\n",
      "img2 with Shift Scale Rotate  .....Saved\n",
      "img3 with Shift Scale Rotate  .....Saved\n",
      "img4 with Shift Scale Rotate  .....Saved\n",
      "img5 with Shift Scale Rotate  .....Saved\n",
      "img6 with Shift Scale Rotate  .....Saved\n",
      "img7 with Shift Scale Rotate  .....Saved\n",
      "img8 with Shift Scale Rotate  .....Saved\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "for id in range(0,9):\n",
    "    fileid = '%05d'%id\n",
    "    IDdirpath = dir + fileid;\n",
    "    \n",
    "    vol_out = np.copy(img[id].get_fdata())\n",
    "    vol_out_m = np.copy(img_mask[id].get_fdata())\n",
    "    transformed = transform(image = vol_out)\n",
    "    transformed_m = transform(image = vol_out_m)\n",
    "    transformed_image = transformed['image']\n",
    "    transformed_Mask = transformed_m['image']\n",
    "    transformed_image = nb.Nifti1Image(transformed_image, affine = img[id].header.get_sform(), header = img[id].header)\n",
    "    transformed_Mask = nb.Nifti1Image(transformed_Mask, affine = img_mask[id].header.get_sform(), header = img_mask[id].header)\n",
    "\n",
    "    #filename = IDdirpath + '/'+ basename + fileid + '_HorF' + fileext\n",
    "    #maskfilename = IDdirpath + '/' + basename + fileid + '___HorF_mask'+ fileext \n",
    "    \n",
    "    #filename = IDdirpath + '/'+ basename + fileid + '_GridDistortion' + fileext\n",
    "    #maskfilename = IDdirpath + '/' + basename + fileid + '___GridDistortion_mask'+ fileext \n",
    "    \n",
    "    #filename = IDdirpath + '/'+ basename + fileid + '_VerF' + fileext\n",
    "    #maskfilename = IDdirpath + '/' + basename + fileid + '___VerF_mask'+ fileext \n",
    "    \n",
    "    #filename = IDdirpath + '/'+ basename + fileid + '_Blur' + fileext\n",
    "    #maskfilename = IDdirpath + '/' + basename + fileid + '___Blur_mask'+ fileext\n",
    "    \n",
    "    #filename = IDdirpath + '/'+ basename + fileid + '_RandomGamma' + fileext\n",
    "    #maskfilename = IDdirpath + '/' + basename + fileid + '___RandomGamma_mask'+ fileext  \n",
    "    \n",
    "    #filename = IDdirpath + '/'+ basename + fileid + '_CentCrop' + fileext\n",
    "    #maskfilename = IDdirpath + '/' + basename + fileid + '___CentCrop_mask'+ fileext  \n",
    "\n",
    "    filename = IDdirpath + '/'+ basename + fileid + '_ShiScaRot' + fileext\n",
    "    maskfilename = IDdirpath + '/' + basename + fileid + '___ShiScaRot_mask'+ fileext \n",
    "    \n",
    "    #name = 'Horizontal Flip'\n",
    "    #name = 'Grid Distortion'\n",
    "    #name = 'Virtical Flip'\n",
    "    #name = 'Blurred'\n",
    "    #name = 'RandomGamma'\n",
    "    #name = 'Center Crop'\n",
    "    name = 'Shift Scale Rotate '\n",
    "    \n",
    "    nb.save(vol_out_inhom,filename) # HorF -> GridDistortion -> Virtical Flip -> Blurred ->RandomGamma ->Center Crop->ShiScaRot\n",
    "    nb.save(vol_out_inhom_m,maskfilename) #\n",
    "    print('img%d with %s .....Saved'%(id,name)) # \n",
    "print ('All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54494d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760fb69d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
