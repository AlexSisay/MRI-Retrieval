{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fae39e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#from torch import nn, optim\n",
    "from torchvision import datasets\n",
    "#from torchvision.transforms import Compose, ToTensor,Normalize\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fb09f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "221de993",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ADNI_Dataset(Dataset):\n",
    "    def __init__(self, transform = None):\n",
    "        #mat_path = './data/ADNI_1_MRI'\n",
    "        data_AD = sio.loadmat('/Users/alex/Documents/Thesis/Jupyter/Test/Test.mat')\n",
    "        Xa, Ya = data_AD['Images'], data_AD['Label']\n",
    "        Xa = np.array(Xa)\n",
    "        Ya = np.array(Ya)\n",
    "        #Xa = Xa.reshape()\n",
    "        print('Type:',type(Xa), 'Shape:', Xa[0].shape)\n",
    "        Xa = Xa.astype('float32')\n",
    "        Xa /= 255                         #normalized to [0,1.0]\n",
    "        Xa = np.expand_dims(Xa, axis = 1) #add channel=1 to the data, n * c * H * W\n",
    "        Ya = Ya.astype('int64')\n",
    "        \n",
    "       \n",
    "        \n",
    "        #XX = np.vstack((Xa))\n",
    "        #YY = np.vstack((Ya))\n",
    "        \n",
    "        self.images = torch.from_numpy(Xa) \n",
    "        self.targets = torch.from_numpy(Ya) \n",
    "        print(self.images.shape)\n",
    "        print(self.targets.shape)\n",
    "        #self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.images[index]\n",
    "        y = self.targets[index]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "class AIBL_Dataset_test(Dataset):\n",
    "    def __init__(self, transform = None):\n",
    "        #mat_path = './data/ADNI_1_MRI'\n",
    "        data_AD = sio.loadmat('/Users/alex/Documents/Thesis/Jupyter/Test/AIBL_AD.mat')\n",
    "        Xa = data_AD['Images']\n",
    "        Xa = Xa.astype('float32')\n",
    "        Xa /= 255                         #normalized to [0,1.0]\n",
    "        Xa = np.expand_dims(Xa, axis = 1) #add channel=1 to the data, n * c * H * W\n",
    "        Ya = np.zeros((len(Xa),1)) \n",
    "        Ya = Ya.astype('int64')\n",
    "        ton = len(Xa)\n",
    "        trn = int(np.round(ton*0.9))\n",
    "        Xa = Xa[trn:,:,:,:]\n",
    "        Ya = Ya[trn:,:]\n",
    "        \n",
    "        data_CN = sio.loadmat('/Users/alex/Documents/Thesis/Jupyter/Test/AIBL_CN.mat')\n",
    "        Xc = data_CN['Images']\n",
    "        Xc = Xc.astype('float32')\n",
    "        Xc /= 255                         #normalized to [0,1.0]\n",
    "        Xc = np.expand_dims(Xc, axis = 1) #add channel=1 to the data, n * c * H * W\n",
    "        Yc = np.zeros((len(Xc),1)) + 1\n",
    "        Yc = Yc.astype('int64')\n",
    "        ton = len(Xc)\n",
    "        trn = int(np.round(ton*0.9))\n",
    "        Xc = Xc[trn:,:,:,:]\n",
    "        Yc = Yc[trn:,:]\n",
    "\n",
    "        data_MCI = sio.loadmat('/Users/alex/Documents/Thesis/Jupyter/Test/AIBL_MCI.mat')\n",
    "        Xm = data_MCI['Images']\n",
    "        Xm = Xm.astype('float32')\n",
    "        Xm /= 255                         #normalized to [0,1.0]\n",
    "        Xm = np.expand_dims(Xm, axis = 1) #add channel=1 to the data, n * c * H * W\n",
    "        Ym = np.zeros((len(Xm),1)) + 2\n",
    "        Ym = Ypm.astype('int64')\n",
    "        ton = len(Xm)\n",
    "        trn = int(np.round(ton*0.9))\n",
    "        Xm = Xm[trn:,:,:,:]\n",
    "        Ym = Ym[trn:,:]\n",
    "        \n",
    "        \n",
    "        XX = np.vstack((Xa,Xc, Xm))\n",
    "        YY = np.vstack((Ya,Yc, Ym))\n",
    "        \n",
    "        self.images = torch.from_numpy(XX) \n",
    "        self.targets = torch.from_numpy(YY) \n",
    "        #self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.images[index]\n",
    "        y = self.targets[index]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "class AIBL_Dataset_train(Dataset):\n",
    "    def __init__(self, transform = None):\n",
    "        #mat_path = './data/ADNI_1_MRI'\n",
    "        data_AD = sio.loadmat('/Users/alex/Documents/Thesis/Jupyter/Test/AIBL_AD.mat')\n",
    "        Xa = data_AD['Images']\n",
    "        Xa = Xa.astype('float32')\n",
    "        Xa /= 255                         #normalized to [0,1.0]\n",
    "        Xa = np.expand_dims(Xa, axis = 1) #add channel=1 to the data, n * c * H * W\n",
    "        Ya = np.zeros((len(Xa),1)) \n",
    "        Ya = Ya.astype('int64')\n",
    "        ton = len(Xa)\n",
    "        trn = int(np.round(ton*0.9))\n",
    "        Xa = Xa[1:trn,:,:,:]\n",
    "        Ya = Ya[1:trn,:]\n",
    "        \n",
    "        data_CN = sio.loadmat('/Users/alex/Documents/Thesis/Jupyter/Test/AIBL_CN.mat')\n",
    "        Xc = data_CN['Images']\n",
    "        Xc = Xc.astype('float32')\n",
    "        Xc /= 255                         #normalized to [0,1.0]\n",
    "        Xc = np.expand_dims(Xc, axis = 1) #add channel=1 to the data, n * c * H * W\n",
    "        Yc = np.zeros((len(Xc),1)) + 1\n",
    "        Yc = Yc.astype('int64')\n",
    "        ton = len(Xc)\n",
    "        trn = int(np.round(ton*0.9))\n",
    "        Xc = Xc[1:trn,:,:,:]\n",
    "        Yc = Yc[1:trn,:]\n",
    "\n",
    "        data_MCI = sio.loadmat('/Users/alex/Documents/Thesis/Jupyter/Test/AIBL_MCI.mat')\n",
    "        Xm = data_MCI['Images']\n",
    "        Xm = Xm.astype('float32')\n",
    "        Xm /= 255                         #normalized to [0,1.0]\n",
    "        Xm = np.expand_dims(Xm, axis = 1) #add channel=1 to the data, n * c * H * W\n",
    "        Ym = np.zeros((len(Xm),1)) + 2\n",
    "        Ym = Ypm.astype('int64')\n",
    "        ton = len(Xm)\n",
    "        trn = int(np.round(ton*0.9))\n",
    "        Xm = Xm[1:trn,:,:,:]\n",
    "        Ym = Ym[1:trn,:]\n",
    "        \n",
    "        \n",
    "        XX = np.vstack((Xa,Xc, Xm))\n",
    "        YY = np.vstack((Ya,Yc, Ym))\n",
    "        \n",
    "        self.images = torch.from_numpy(XX) \n",
    "        self.targets = torch.from_numpy(YY) \n",
    "        #self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.images[index]\n",
    "        y = self.targets[index]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51be8ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'numpy.ndarray'> Shape: (182, 218, 182)\n",
      "torch.Size([39, 1, 182, 218, 182])\n",
      "torch.Size([39, 3])\n",
      "data loaded...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = ADNI_Dataset()\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True) \n",
    "print('data loaded...\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcad08c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = trainloader.dataset.data \n",
    "#shape = trainloader.dataset.data.shape  \n",
    "#datatype = trainloader.dataset.data.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b064d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72659521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad852ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##############################################################\n",
    "\n",
    "        \n",
    "class AD_3DCNN(nn.Module):\n",
    "    \"\"\"The model we use in the paper.\"\"\"\n",
    "    \n",
    "    def __init__(self, code_len = 16, label_len = 2,  dropout=0):\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "        self.code_length = code_len\n",
    "        self.label_length = label_len\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv3d(1, 8, 3), #conv1\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv3d(8, 8, 3), #conv2\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.MaxPool3d(2,stride =2),\n",
    "            nn.ReLU(),\n",
    "            ################################\n",
    "            nn.Conv3d(8, 16, 3), #conv3\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv3d(16, 16, 3), #conv4\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.MaxPool3d(2,stride =2),\n",
    "            nn.ReLU(),\n",
    "            ####################################\n",
    "            nn.Conv3d(16, 32, 3), #conv5\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv3d(32, 32, 3), #conv6\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.MaxPool3d(2,stride =2),\n",
    "            nn.ReLU(),\n",
    "            ###################################\n",
    "            nn.Conv3d(32, 64, 3), #conv7\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv3d(64, 64, 3), #conv8\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.MaxPool3d(2,stride =2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            #####################################\n",
    "            #nn.Conv3d(64, 20, 3), #conv10\n",
    "            #nn.BatchNorm3d(20),\n",
    "            #nn.MaxPool3d(2,stride =2),\n",
    "            #nn.ReLU(),\n",
    "            ######################################\n",
    "            nn.Conv3d(64, 128, 3), #conv9\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv3d(128, 128, 3), #conv10\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.MaxPool3d(2,stride =2),\n",
    "            nn.ReLU(),\n",
    "                 \n",
    "        )    \n",
    "            \n",
    "        \n",
    "        self.classifier3 = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, self.label_length),\n",
    "        )\n",
    "        self.codes3 = nn.Sequential(\n",
    "            nn.Linear(256, self.code_length),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "        self.codes_classifier3 = nn.Sequential(\n",
    "            nn.Linear(self.code_length, self.label_length),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        features = features.view(x.shape[0], -1)\n",
    "        logits = self.classifier3(features)\n",
    "        return logits\n",
    "\n",
    "    def extract_codes_and_logits(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        features = features.view(x.shape[0], -1)\n",
    "        codes = self.codes3(features)\n",
    "        logits = self.codes_classifier3(codes)\n",
    "        return  codes, logits\n",
    "        #return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54934260",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e6741e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'numpy.ndarray'> Shape: (182, 218, 182)\n",
      "torch.Size([39, 1, 182, 218, 182])\n",
      "torch.Size([39, 3])\n",
      "data loaded...\n",
      "\n",
      "AD_3DCNN(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv3d(1, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "    (1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "    (4): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): ReLU()\n",
      "    (7): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "    (8): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU()\n",
      "    (10): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "    (11): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (13): ReLU()\n",
      "    (14): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "    (15): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU()\n",
      "    (17): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "    (18): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (20): ReLU()\n",
      "    (21): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "    (22): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (23): ReLU()\n",
      "    (24): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "    (25): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (27): ReLU()\n",
      "    (28): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "    (29): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (30): ReLU()\n",
      "    (31): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "    (32): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (33): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): ReLU()\n",
      "  )\n",
      "  (classifier3): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=256, out_features=2, bias=True)\n",
      "  )\n",
      "  (codes3): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=16, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      "  (codes_classifier3): Sequential(\n",
      "    (0): Linear(in_features=16, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "cpu\n",
      "Epoch:1\n",
      "loss:4.966473579406738\n",
      "loss:1.9536223411560059\n",
      "loss:1.934359073638916\n",
      "loss:1.7839806079864502\n",
      "loss:2.7290167808532715\n",
      "loss:2.4949090480804443\n",
      "loss:4.346198081970215\n",
      "loss:5.929219722747803\n",
      "loss:3.6652979850769043\n",
      "loss:4.907261371612549\n",
      "loss:3.2084131240844727\n",
      "loss:2.8040575981140137\n",
      "loss:2.563889503479004\n",
      "loss:3.0686492919921875\n",
      "loss:2.292313575744629\n",
      "loss:3.3449325561523438\n",
      "loss:2.4857234954833984\n",
      "loss:6.615095138549805\n",
      "loss:4.203897476196289\n",
      "loss:8.322545051574707\n",
      "Epoch:2\n",
      "loss:11.149486541748047\n",
      "loss:4.48932409286499\n",
      "loss:4.608188629150391\n",
      "loss:4.312744140625\n",
      "loss:3.7999520301818848\n",
      "loss:1.591575026512146\n",
      "loss:2.3896636962890625\n",
      "loss:2.001636266708374\n",
      "loss:3.09354829788208\n",
      "loss:3.193666458129883\n",
      "loss:3.526975631713867\n",
      "loss:5.249756336212158\n",
      "loss:2.4276976585388184\n",
      "loss:4.448005199432373\n",
      "loss:3.667555809020996\n",
      "loss:2.8260388374328613\n",
      "loss:1.4183323383331299\n",
      "loss:2.5953168869018555\n",
      "loss:2.5735702514648438\n",
      "loss:3.384101152420044\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms \n",
    "import numpy as np\n",
    "from time import time\n",
    "from losses import *\n",
    "import os\n",
    "import copy\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "\n",
    "import pdb\n",
    "\n",
    "########################################################################\n",
    "def momentum_update(model_q, model_k, beta = 0.999):\n",
    "    param_k = model_k.state_dict()\n",
    "    param_q = model_q.named_parameters()\n",
    "    for n, q in param_q:\n",
    "        if n in param_k:\n",
    "            param_k[n].data.copy_(beta*param_k[n].data + (1-beta)*q.data)\n",
    "    model_k.load_state_dict(param_k)\n",
    "\n",
    "def queue_data(data, k):\n",
    "    return torch.cat([data, k], dim=0)\n",
    "\n",
    "def dequeue_data(data, K=8):\n",
    "    if len(data) > K:\n",
    "        return data[-K:]\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def initialize_queue(model_k, device, train_loader, batch_size, queue_size):\n",
    "    #queue = torch.zeros((0, 240), dtype=torch.float) \n",
    "    queue = torch.zeros((0, 2), dtype=torch.float) \n",
    "    #label_queue = torch.zeros((0), dtype=torch.float) \n",
    "    queue = queue.to(device)\n",
    "    #label_queue = label_queue.to(device)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        x_k = data\n",
    "        x_k = x_k.to(device)\n",
    "        k = model_k(x_k)\n",
    "        k = k.detach()\n",
    "        queue = queue_data(queue, k)\n",
    "        queue = dequeue_data(queue, K = queue_size)\n",
    "\n",
    "        #label_k = target\n",
    "        #label_k = label_k.squeeze(1)\n",
    "        #label_k = label_k.to(device)\n",
    "        #label_k = label_k.float()\n",
    "        #label_queue = queue_data(label_queue, label_k)\n",
    "        #label_queue = dequeue_data(label_queue, K = queue_size)\n",
    "        break\n",
    "    return queue#, label_queue\n",
    "\n",
    "def train(model_q, model_k, device, train_loader, queue,  optimizer, epoch, temp=0.07):\n",
    "    model_q.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        x_q = data\n",
    "        #pdb.set_trace()\n",
    "        x_q = x_q.to(device)\n",
    "        output_q = model_q(x_q)\n",
    "        concat_q = torch.cat([queue, output_q], dim = 0)\n",
    "        N = x_q.shape[0]\n",
    "        K = concat_q.shape[0]\n",
    "        logits = torch.mm(output_q.view(N, -1), concat_q.T.view(-1, K))\n",
    "        labels = torch.zeros(N, dtype = torch.long)\n",
    "        labels = labels.to(device)\n",
    "        loss = loss_function(logits, labels)\n",
    "        print ('loss:{}'.format(loss))\n",
    "        \n",
    "        #target = target.squeeze(1)\n",
    "        #target = target.to(device)\n",
    "        #target = target.float()\n",
    "        ##pdb.set_trace()\n",
    "        #concat_labels = torch.cat([label_queue, target], dim = 0)\n",
    "        #concat_labels = concat_labels.long()\n",
    "        #loss = loss_function(concat_q, concat_labels)\n",
    "        #print 'loss:{}'.format(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        m_outputs = model_k(x_q)\n",
    "        m_outputs = m_outputs.detach()\n",
    "        #m_outputs2 = copy.deepcopy(m_outputs)\n",
    "        queue = queue_data(queue, m_outputs)\n",
    "        queue = dequeue_data(queue)\n",
    "        #label_queue = queue_data(label_queue, target)\n",
    "        #label_queue = dequeue_data(label_queue)\n",
    "if __name__ == '__main__':     \n",
    "    dataset = ADNI_Dataset()\n",
    "    trainloader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "    testloader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True) \n",
    "    print('data loaded...\\n')\n",
    "\n",
    "    net = AD_3DCNN(dropout=0.5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    print(net)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if torch.cuda.device_count() > 1:\n",
    "      print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "      net = nn.DataParallel(net)\n",
    "    \n",
    "    print(device)\n",
    "    net.to(device)\n",
    "    m_net = copy.deepcopy(net)\n",
    "    #queue, label_queue = initialize_queue(m_net, device, trainloader, batch_size = 1, queue_size = 10)\n",
    "    queue = initialize_queue(m_net, device, trainloader, batch_size = 2, queue_size = 10)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
    "    for epoch in range(1,3):  # loop over the dataset multiple times\n",
    "        print('Epoch:{}'.format(epoch))\n",
    "        train(net, m_net, device, trainloader, queue, optimizer, epoch)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03e8b592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0198, 0.9942],\n",
       "        [0.4938, 0.6087]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "810f7c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83a112ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = 0.999\n",
    "param_k = m_net.state_dict()\n",
    "param_q = net.named_parameters()\n",
    "for n, q in param_q:\n",
    "    if n in param_k:\n",
    "        param_k[n].data.copy_(beta*param_k[n].data + (1-beta)*q.data)\n",
    "m_net.load_state_dict(param_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "822d4280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_k.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fb611d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f56469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aa506d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9f238b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
